<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Scientific Workflows</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m32861</md:content-id>
  <md:title>Scientific Workflows</md:title>
  <md:abstract>This chapter describes the advantages of using scientific workflows in data-intensive research.</md:abstract>
  <md:uuid>8fedc2ef-93a4-4f55-9bca-52820a2586b7</md:uuid>
</metadata>
<featured-links>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit below.
       Changes to the links section in the source will not be saved. -->
    <link-group type="supplemental">
      <link url="http://cnx.org/content/m32860/latest/" strength="3">Scholarly Communications and the Web - more on myExperiment</link>
    </link-group>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit above.
       Changes to the links section in the source will not be saved. -->
</featured-links>
<content>
    
    <para id="id6139448">
<title>Key Concepts:</title>
    <list id="id6272259" list-type="bulleted">
      <item>Scientific workflows</item>
      <item>Data-intensive research</item>
    </list>
</para>
    <section id="id5527603">
      <title>Introduction</title>
      
      <para id="id4850910">The use of data processing workflows within the business sector has been commonplace for many years. Their use within the scientific community, however, has only just begun. With the uptake of workflows within scientific research, an unprecedented level of data analyses is now at the fingertips of individual researchers, leading to a change in the way research is carried out. This chapter describes the advantages of using workflows in modern biological research; demonstrating research from the field where the application of workflow technologies was vital for understanding the processes involved in resistance and susceptibility of infection by a parasite. Specific attention is drawn to the Taverna Workflow Workbench (Hull <emphasis effect="italics">et al.</emphasis> 2006), a workflow management system that provides a suite of tools to support the design, execution, and management of complex analyses in the data intensive research, for example, in the Life Sciences.</para>
    </section>
    <section id="id6915083"><title>Data-Intensive Research in the Life Sciences</title><para id="id6917525">In the last decade the field of informatics has moved from the fringes of biological and biomedical sciences to being an essential part of research. From the early days of gene and protein sequence analysis, to the high-throughput sequencing of whole genomes, informatics is integral in the analysis, interpretation, and understanding of biological data. The post-genomic era has been witness to an exponential rise in the generation of biological data; the majority of which is freely available in the public domain, and accessible over the Internet. </para>
      <para id="id6383383">New techniques and technologies are continuously emerging to increase the speed of data production. As a result, the generation of novel biological hypotheses has shifted from the task of data generation to that of data analysis. The results of such high-throughput investigations, and the way it is published and shared, is initially for the benefit of the research groups generating the data; yet it is fundamental to many other investigations and research institutes. The public availability means that it can then be reused in the day to day work of many other scientists. This is true for most bioinformatics resources. The overall effect, however, is the accumulation of useful biological resources over time.</para>
      
      <para id="id6383045">In the 2009 <emphasis effect="italics">Databases</emphasis> special issue of <emphasis effect="italics">Nucleic Acids Research</emphasis>, over 1000 different biological databases were available to the scientific community. Many of these data resources have associated analysis tools and search algorithms, increasing the number of possible tools and resources to several thousand. These resources have been developed over time by different institutions. Consequently, they are distributed and highly heterogeneous with few standards for data representation or data access. Therefore, despite the availability of these resources, integration and interoperability present significant challenges to researchers. </para>
      <para id="id6382561">In bioinformatics, many of the major service providers are providing <link document="m32631" target-id="webService">Web Service</link>  interfaces to their resources, including the NCBI, EBI, and DDBJ; many more are embracing this technology each year. This widespread adoption of Web Services has enabled workflows to be more commonly used within scientific research. Data held in the NCBI can now be analysed with tools available at the EBI, within analysis pipeline. </para>
    </section>
    <section id="id6382669">
      <title>In Silico Workflows</title>
      <para id="id6382481">One possible solution to the problem of integrating heterogeneous resources is the use of <emphasis effect="italics">in silico workflows. </emphasis>The use of workflows in science has only emerged over the last few years and addresses different concerns to workflows used within the business sector. Rather than co-ordinating the management and transactions between corporate resources, scientific workflows are used to automate the analysis of data through multiple, distributed data resources in order to execute complex <emphasis effect="italics">in silico</emphasis> experiments. </para>
      <para id="id6386017">Workflows provide a mechanism for accessing remote third-party services and components. This in turn reduces the overheads of downloading, installing, and maintaining resources locally whilst ensuring access to the latest versions of data and tools. Additionally, much of the computation happens remotely (on dedicated servers). This allows complex and computationally intensive workflows to be executed from basic desktop or laptop computers. As a result, the researchers are not held back by a lack of computational resources or access to data.</para>
      
      <para id="id6404631">A workflow provides an abstracted view over the experiment being performed. It describes <emphasis effect="italics">what</emphasis> analyses will be executed, not the low-level details of <emphasis effect="italics">how</emphasis> they will be executed; the user does not need to understand the underlying code, but only the scientific protocol. This protocol can be easily understood by others, so can be reused or even altered and repurposed. Workflows are a suitable technology in any case where scientists need to automate data processing through a series of analysis steps. Such mechanisms have the potential to increase the rate of data analysis, from a cottage-scale to industrial scale operation.</para>
      <para id="id6404692">There are many workflow management systems available in the scientific domain, including: Taverna (Hull <emphasis effect="italics">et al</emphasis>. 2006), Kepler (Altintas <emphasis effect="italics">et al.</emphasis> 2004) and Triana (Taylor <emphasis effect="italics">et al.</emphasis> 2003). Taverna, developed by the the myGrid consortium (http://www.mygrid.org.uk/), is a workflow system that was built with the Life Sciences in mind but it has since been used in other fields as well, including Physics, Astronomy and Chemistry. Like many others, the Taverna Workbench provides: </para>
      <list id="id6405026" list-type="bulleted">
        <item>an environment for designing workflows; </item>
        <item>an enactment engine to execute workflow locally or remotely; </item>
        <item>support for workflow design in the form of service and workflow discovery; </item>
        <item>and provenance services to manage the results and events of workflow invocations. </item>
      </list>
    </section>
    <section id="id6405066">
      <title>Understanding Disease Resistance in Model Organisms</title>
      <para id="id6405078">Taverna workflows are used in many areas of Life Science research, notably for research into genotype-phenotype correlations, proteomics, genome annotation, and Systems Biology. The following case study demonstrates the use of Taverna workflows in the Life Sciences domain for genotype-phenotype studies (Stevens <emphasis effect="italics">et al</emphasis>. 2008). </para>
      <figure id="id6405134">
        <media id="id6405134_media" alt="">
          <image mime-type="image/png" src="../../media/graphics1-d945.png" id="id6405134__onlineimage" height="351" width="576"/>
        </media>
<caption>This figure shows the conversion of a microarray CEL image file to a list of candidate genes, pathways, and pathway publications. The workflow makes use of a local statistical processor, services from the National Centre for Biotechnological Innovation (NCBI) and the Kyoto Ecyclopedia of Genes and Genomes (KEGG)</caption>
      </figure>
      <para id="id6405221">Sleeping sickness (or African trypanosomiasis) is an endemic disease throughout the sub-Saharan region of Africa. It is the result of infection from the trypanosome parasite, affecting a host of organisms. The inability of the agriculturally productive Boran cattle species to resist trypanosome infection is a major restriction within this region. The Nâ€™Dama species of cattle, however, has shown tolerance to infection and its subsequent disease. The low milk yields and lack of physical strength of this breed, unfortunately, limit their use in farming or meat production. A better understanding of the processes that govern the characteristics of resistance or susceptibility in different breeds of cattle will potentially lead to the development of novel therapeutic drugs or the construction of informed selective breeding programs for enhancing agricultural production. </para>
      <para id="id6405465">Research conducted by the Wellcome Trust <link url="http://www.genomics.liv.ac.uk/tryps/index.php">Host-Pathogen </link> project is currently investigating the mechanisms of resistance to this parasitic infection, utilising Taverna workflows for a large-scale analysis of complex biological data (Fisher <emphasis effect="italics">et al</emphasis>. 2007). The workflows in this study combine two approaches to identify candidate genes and their subsequent biological pathways: classic genetic mapping can identify chromosomal regions that contain genes involved in the expression of a trait (Quantitative Trait Loci or QTL) while transcriptomics can reveal differential gene expression levels in susceptible and resistant species. </para>
      <para id="id6405615">Previous studies using the mouse as model organism identified 3 chromosomal regions statistically linked to resistance to trypanosome infection. One of these regions, the Tir1 QTL, showed the largest effect on survival. Previous investigations using this QTL identified a region shared between the mouse and cow genomes. As the scale of the data analysis task is large, researchers performing such an analysis manually would often triage their data and in this case have tended to focus on this shared region in their search for candidate genes contributing to the susceptibility to trypanosome infection. While this approach may be scientifically valid, there is a danger that candidate genes may be missed where additional biological factors may contribute to the expression of the phenotype. With a workflow, this triage of data is no longer necessary. <emphasis effect="italics">All</emphasis> data can be analysed systematically, reducing the risk of missing vital information. </para>
      <para id="id6405740">Researchers on the Wellcome Trust Pathogen-Host project conducted a wider analysis of the entire QTL region using a set of workflows to identify pathways whose genes lie within the chosen QTL region, and contain genes whose expression level changes. As a result of this research, a key pathway was identified whose component genes showed differential expression following infection from the trypanosome parasite. Further analysis showed that, within this pathway, the Daxx gene is located within the Tir1 QTL region and showed the strongest change in expression level. Subsequent investigations using the scientific literature highlighted the potential role of Daxx in contributing to the susceptibility to trypanosome infection. This prompted the re-sequencing of Daxx within the laboratory, leading to the identification of mutations of the gene within the susceptible mouse strains. Previous studies had failed to identify this as a candidate gene due to the premature triage of the QTL down to the syntenous region.</para>
      <para id="id6405991">This example shows that conducting this kind of data-driven approach to analysing complex biological data at the level of biological pathways can provide detailed information of the molecular processes contributing to the expression of these traits. The success of this work was primarily in data integration and the ability of the workflow to process large amounts of data in a consistent and automated fashion.</para>
    </section>
    <section id="id6406201">
      <title>Workflow Reuse</title>
      <para id="id6406207">Workflows not only provide a description of the analysis being performed, but also serve as a permanent record of the experiment when coupled with the results and provenance of workflow runs. Researchers can verify past results by re-running the workflow or by exploring the intermediate results from past invocations. The same workflow can also be used with new data or modified and reused for further investigations. </para>
      <para id="id6406274">The ability to reuse workflows and to automatically record provenance of workflow runs gives workflow management systems a large advantage over manual analysis methods and scripting. Manual analysis techniques are inherently difficult to replicate and are compounded by poor documentation. An example is the wide-spread use of â€˜link integrationâ€™ in bioinformatics (Stein 2003). This process, of hyper-linking through any number of data resources, further exacerbates the problem of capturing the methods used for obtaining <emphasis effect="italics">in silico</emphasis> results where it is often difficult to identify the essential data in the chain of hyper-linked resources. </para>
      <para id="id6406312">Workflow reuse is also an important area within the sciences, and provides a mechanism for sharing methodologies and analysis protocols. As a result, repositories for finding and sharing workflows are emerging. One such resource, <link url="http://myexperiment.org">myExperiment</link>, developed in collaboration between the Universities of Manchester and Southampton, provides a workflow repository and a collaborative social networking environment to support the <emphasis effect="italics">in silico</emphasis> experimental process, and to enable scientists to connect with those with similar interests. The workflows dicussed in the trypanosomiasis use-case study are <link url="http://www.myexperiment.org/packs/83">available on myExperiment</link>, as part of a workflow pack. Many of these have already been reused in other studies. One such example includes the re-purposing of the microarray gene expression workflow to analyse gene expression data from <emphasis effect="italics">E. Coli</emphasis>. <link url="http://www.myexperiment.org/workflows/187">This workflow</link> appends a further workflow to include a means of information retrieval for future text mining applications (shown in Figure 1). </para>
    </section>
    <section id="id6406701">
      <title>Discussion</title>
      <para id="id6406707">Manually processing and examining results in biology is no longer feasible for many scientists. Data is dynamic, distributed, and often very large. This will not change in the near future.</para>
      <para id="id6406729">The integration and interoperation of data between different and distributed resources is a vital part of almost all experiments. With the exception of a few supercomputing centres, most institutions do not have the storage, computational, or curation facilities to consider integrating resources locally. The ability to access and utilise many different resources from all over the world is consequently a large advantage of workflow technologies. It allows scientists to access computing resources far beyond the power available through their own desktop machines.</para>
      <para id="id6406783">Building workflows is a practical solution to problems involving access to data and applications, but care still needs to be taken to exploit these advantages. Interoperation without integration may lead to unmanageable results which are difficult to analyse. In this event, the problem has not been solved, but simply transferred further downstream. Considering <emphasis effect="italics">how</emphasis> results will be used and <emphasis effect="italics">who</emphasis> will be analysing them is important. For example, designing workflows to populate a data model, or to feed into external visualization software, could reduce these problems. The provenance traces of the workflow runs can also help scientists to explore their results. </para>
      <para id="id6406803">Designing these â€˜advancedâ€™ workflows requires a significant amount of informatics knowledge that many laboratory researchers cannot be expected to have. They do, however, need to use tools and software to analyse their data. The introduction of workflow repositories, like myExperiment, provides the wider research communities with access to pre-configured, complex workflows. Researchers can re-use established analysis protocols by downloading and running them with their own data. In some circumstances, they can even run Taverna workflows through the myExperiment interface. </para>
      <para id="id6406874">Increasingly, workflows are becoming applications that are hidden behind web pages like myExperiment, or other domain specific portals. Instead of stand-alone tools, they are becoming integral parts of virtual research environments, or e-Laboratories. Users may not necessarily know they are invoking workflows. </para>
      <para id="id6406896">The use of workflows in research can reduce many problems associated with data distribution and size. In the post-genomic era of biology, for example, this is extremely important. Biomedical science is a multidisciplinary activity which can benefit from advances e-Science in equal measure to advances in laboratory techniques. Sharing workflows and <emphasis effect="italics">in silico</emphasis> analysis methods, with tools like Taverna and myExperiment, can lead to significant contributions to research in this and other disciplines. </para>
    </section>
    <section id="id6406945"><title>References</title><para id="id6406957">Altintas, I. <emphasis effect="italics">et al.</emphasis> (2004). Kepler: an extensible system for design and execution of scientific workflows. <emphasis effect="italics">Proceedings of the 16th International Conference on Scientific and Statistical Database Management</emphasis></para>

<para id="eip-189">Fisher, P., Hedeler, C., Wolstencroft, K., Hulme, H., Noyes, H., Kemp, S., Stevens, R. and Brass, A. (2007). A systematic strategy for large-scale analysis of genotype phenotype correlations: identification of candidate genes involved in African trypanosomiasis. <emphasis effect="italics">Nucleic Acids Resesearch</emphasis>, 35(16). pp. 5625-5633.</para><para id="eip-479">Hull, D., Wolstencroft, K., Stevens, R., Goble, C., Pocock, M., Li, P. and Oinn, T. (2006). Taverna: a tool for building and running workflows of services. <emphasis effect="italics">Nucleic Acids Research</emphasis>, vol. 34, Web Server issue, W729-W732.</para><para id="id6407045">Stein, L. (2003). Integrating biological databases. <emphasis effect="italics">Nat Rev Genet</emphasis>, 4(5). pp. 337-345.</para>

<para id="id6407009">Stevens, R. <emphasis effect="italics">et al.</emphasis> (2004). Exploring Williams-Beuren syndrome using myGrid. <emphasis effect="italics"> Bioinformatics</emphasis>, 20 Suppl 1</para>

<para id="id6407027">Stevens, R. et al. (2008). Traversing the bioinformatics landscape. W. Dubitzky (ed.) <emphasis effect="italics">Data Mining Techniques in Grid Computing Environments</emphasis>. John Wiley and Sons. pp. 141-164.</para>

<para id="id6406979">Taylor, I. <emphasis effect="italics">et al.</emphasis> (2003). Triana Applications within Grid Computing and Peer to Peer Environments. <emphasis effect="italics">Journal of Grid Computing</emphasis>, 1(2). pp. 199-217.</para>    </section>
  </content>
</document>